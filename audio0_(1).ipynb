{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C6Y7MUPBSi_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Installer les d√©pendances\n",
        "!pip install pydub transformers torchaudio\n",
        "\n",
        "# üîä Chargement et re-√©chantillonnage\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "# üß† Transcription avec Wav2Vec2.0\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "import torch\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ],
      "metadata": {
        "id": "8dYCwX-TYpaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aaf395d"
      },
      "source": [
        "!apt-get install ffmpeg -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9c22d74"
      },
      "source": [
        "from google.colab import files\n",
        "from pydub import AudioSegment\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "import torch\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "  # üîÑ Conversion M4A ‚Üí WAV\n",
        "  filename = fn\n",
        "  audio = AudioSegment.from_file(filename, format=\"m4a\")\n",
        "  audio.export(\"converted.wav\", format=\"wav\")\n",
        "\n",
        "  # üîä Chargement et re-√©chantillonnage\n",
        "  waveform, sample_rate = torchaudio.load(\"converted.wav\")\n",
        "  resampler = T.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "  waveform_resampled = resampler(waveform)\n",
        "\n",
        "  # üß† Transcription avec Wav2Vec2.0\n",
        "  processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "  model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "  input_values = processor(waveform_resampled.squeeze(), sampling_rate=16000, return_tensors=\"pt\").input_values\n",
        "  logits = model(input_values).logits\n",
        "  predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "  transcription = processor.decode(predicted_ids[0])\n",
        "  print(\"üìù Transcription :\", transcription)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}